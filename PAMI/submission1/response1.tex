\documentclass[11pt]{article}
\input{/Users/jovo/Research/latex/latex_document}

\title{Response to Review of TPAMI-2011-11-0845}
\author{Vogelstein et al.}

\begin{document}
\maketitle

We would like to thank the two helpful reviewers and the editor for their insightful comments.  We have extensively revised the manuscript in light of the comments we received.  Below are a few general remarks about the current revision, followed by specific responses to reviewer comments (reviewer comments are in \textbf{bold}):

\begin{itemize}
	\item  We have significantly revised the introductory sections (\S 1-2) to clarify that we have devised a fast and \emph{approximate} algorithm for solving quadratic assignment problems (QAP).  That graph matching can be cast as a QAP is useful because it ties our algorithm into a greater literature on QAP.	We were motivated to derive an approximate solution because our application of interest has between hundreds and billions of vertices, so exact algorithms are completely out of the question.  We hope that the text of this version of the manuscript conveys that sentiment clearly.  In fact, although our algorithm seems to be the best cubic-time approximate algorithm for solving graph matching problems, it is not nearly fast enough.  The incoming massive brain-graph data will hopefully motivate others to further improve on our work, which we view merely as a starting point.
	\item Our algorithm now fundamentally has an initial starting position that is fixed (\S 5).  This is despite that the problem we seek to solve is non-convex, and we do not convexify it.  However, by starting at a sensible initial condition (the barycenter of the feasible region), we found that our algorithm outperforms the previous state of the art on 12 of the 16 benchmarks.  
	\item Submission of this manuscript to TPAMI was motivated by our reading of the very nice paper of Zaslavskiy et al. (reference [29] in the current revision), which was recently published in TPAMI.  Zaslavskiy developed a novel PATH following algorithm, that was demonstrated to exceed the previous state of the art on 14 of 16 benchmark datasets selected from the QAP library (reference [4]).  Although the authors of that manuscript did not explain their choice of 16, it is the exact same 16 used in a previous comparison of various approximate graph matching algorithms (reference [30]). Moreover, in [30], the authors explain that their choice of those 16 of the $>$100 datasets was based on those being ``particularly difficult''.   Our algorithm outperformed the PATH algorithm on 12 of the 16 datasets.  If we elect to use multiple restarts, which we can only fruitfully do because our objective function is non-convex, we outperform all previous algorithms on all datasets we considered.
\end{itemize}
 





% We respond to each specific comment below.

\newpage
\section{Reviewer: 1}

\begin{itemize}
	\item \textbf{1) A principle flaw:
	The suggested approach samples an generally NP-problem at n=1,3 or 100
	random points and search for a local minima in
	the usually highly non-convex function (the relaxed QAP).
	So, for increasing problem size the probability
	to obtain a good solution drops drastically.
	}

	In the original draft of this manuscript, we overemphasized the multiple restart aspect of this work.  In fact, our algorithm outperforms the previous state of the art cubic-time QAP algorithms on 12 of the 16 benchmarks. We have substantially revised the text to reflect this.  Specifically, in the first step of \S 5, we now write:
	
	\begin{quote}
		\textbf{I: Find a suitable initial position $P^{(0)} \in \mc{D}$}  While any doubly stochastic matrix would be a feasible initial point, two choices seem natural: (i) the ``flat doubly  stochastic matrix,'' $J=\ve{1} \cdot \ve{1}\T/n$, which is the center of the feasible region, and (ii) the identity matrix, which is a permutation matrix.  We elect to use the flat matrix as our default initial starting point.
	
	\end{quote} 
	
		We have added a subsection in the results to merely remark that multiple restarts are a possibility (\S 6.4). %merely commenting on the multiple restart option in a subsection. %We regrettably failed to clarify in the results that performance on the brain-graph matching task was repeated 10 times to demonstrate the repeatability of these results.

	\item \textbf{2) Insufficient evaluation:
	A report on statistical properties of the approach
	would make an evaluation of the method possible, i.e, how often
	is the best solution found by the sampling depending on the
	the problem size.
	However such information is not provided in the report.
	}
	
	
	% Indeed, because our approach seeks to solve a non-convex optimization problem, it is natural to wonder how often the best solution is found for certain problems.  
	We have modified the Brain-Graph Matching section (\S 6.5) to emphasize that the results are averaged over 10 trials. Specifically, we have added the following sentence:
	
	\begin{quote}
Then, we tried to graph match $A_z$ to $B_z^{(k)}$, for $z \in \{e,c\}$ and for $k \in [10]$, that is, we repeat the experiment 10 times. 
	\end{quote}

	\item \textbf{3) Too few experiments:
	The authors have performed 16 experiments on
	the qaplib dataset which has in its standard form
	more than 100 problem instances.
	}

	The 16 that we used were exactly the 16 datasets used in recent TPAMI publication on the PATH algorithm for graph matching (now reference [29]).  Moreover, although the authors of the PATH paper did not explain their choice of 16, they are the same 16 used in reference [30], in which several different graph matching algorithms were compared.  In [30], it was explained that these 16 are ``particularly difficult''.  \S 6.3 elaborates on this in the text:
	
	\begin{quote}
		Specifically, [29] created a path following algorithm (\texttt{PATH}) based on a convex and concave relaxation of QAP. In that manuscript, the authors considered 16 datasets from the QAP benchmark, the same 16 datasets as were used in [30], which are known to be ``particularly difficult''. 
	\end{quote}
	
	\item \textbf{Developments reported for example in
``N. Brixius and K. Anstreicher. Solving quadratic assignment problems
using convex quadratic programing relaxations. Optimization Methods
and Software.'' are completely ignored.
}


We regret that we failed to clarify that our algorithm, like PATH, outperformed all the algorithms considered in the above mentioned very valuable citation.  This omission has been corrected in \S 6.3:

	\begin{quote}
Specifically, \texttt{PATH} was compared to the Quadratic Programming Bound approach (\texttt{QGP}) of [31], the graduated assignment algorithm (\texttt{GRAD}) of [32], and Umeyama's algorithm (\texttt{U}) [33].  Because either \texttt{PATH} or \texttt{QBP} outperformed \texttt{GRAD} and \texttt{U} on every dataset, Table 1 shows the performance of \faqap versus \texttt{PATH} and \texttt{QBP}. 
	\end{quote}

	\item \textbf{On a different level it seems a bit unrealistic to assume that all the
graphs they wish to compare are of equal size, however
it is not discussed or even mentioned why the authors have
reason to assume that the graphs are equally sized.}


Indeed, although for some brain-graphs the number of vertices will be the same, for many, they will not be.  We have modified the \S 7 accordingly:

 	\begin{quote}
		Second, for many brain-graph matching problems, the number of vertices will not be the same across the brains.  Recent work from [29],[38]  and [39] suggest that extensions in this direction would be both relatively straightforward and effective. 
	\end{quote}

	\item \textbf{The authors report a good performance on a quite large graph with
302 nodes, but do not indicate how the graph looks like. That
makes it difficult to speculate about reasons that make this problem
solvable by just sampling at a few positions followed by the Frank-Wolfe
algorithm. It might be that the structure of the problem is
more easy (Can the assignment be found by a spectral analysis of the
adjacency matrix?)
}

We have clarified the text (\S 6.5) to point out extensive analyses of the brain-graphs by reference [37]:

	\begin{quote}
		The properties of these connectomes are analyzed in [37], but it remains unclear to us why the chemical connectome was so much easier to graph match than the electrical one.
	\end{quote}
		

	\item \textbf{minor comments: (The line numbers at the beginning refer to both columns...)
}

Thank you, we have corrected all the minor comments.

\end{itemize}


\newpage
\section{Reviewer 2} % (fold)
\label{sec:reviewer_2}

\begin{itemize}
	\item \textbf{Though this is a proposal of a QAP inexact solver, it is in principle limited to graphs of the same size.}

We have now mentioned the possibility of extending this work to deal with different numbers of vertices, and have referenced both Zaslavskiy et al. 2010 and Escolano et al. 2011 (references [38] and [39], respectively).	We have modified the \S 7 accordingly:

	 	\begin{quote}
			Second, for many brain-graph matching problems, the number of vertices will not be the same across the brains.  Recent work from [29],[38]  and [39] suggest that extensions in this direction would be both relatively straightforward and effective. 
		\end{quote}

	\item \textbf{Even in this case, there is no reference neither experimental nor theoretical to the GA (Graduated Assignment) Algorithm (Gold and Rangarajan, PAMI'1996). }

We have now clarified that our algorithm outperforms the GRAD algorithm on all benchmarks tested (\S 6.3).  

	\begin{quote}
Specifically, \texttt{PATH} was compared to the Quadratic Programming Bound approach (\texttt{QGP}) of [31], the graduated assignment algorithm (\texttt{GRAD}) of [32], and Umeyama's algorithm (\texttt{U}) [33].  Because either \texttt{PATH} or \texttt{QBP} outperformed \texttt{GRAD} and \texttt{U} on every dataset, Table 1 shows the performance of \faqap versus \texttt{PATH} and \texttt{QBP}. 
	\end{quote}


% \begin{quote}
% Because either \texttt{PATH} or \texttt{QBP} outperformed \texttt{GRAD} and \texttt{U} on every dataset, Table 1 shows the performance of \faqap versus \texttt{PATH} and \texttt{QBP}. 
% \end{quote}

	\item \textbf{This is quite simplistic when comparing to the power of deterministic annealing implicit in GA to avoid local minima. A serious comparison between both schemes should be desirable.}

Because our algorithm outperformed a previously published algorithm in TPAMI which outperformed GA (the PATH algorithm), this seemed unnecessary.

	\item \textbf{In [25] it is proposed an algoritmh outperforming QBP. The method proposed here is quite similar to that in [25] (which is more focused on labeled graphs but based on FW) so I judge the proposal quite incremental.}

Indeed, our algorithm is similar to [25].  Yet, our algorithm outperforms [25] on 12 of 16 benchmarks, which we believe to be significant.  Moreover, [25] is fundamentally flawed, in that they claim to have a PATH following algorithm between a convex and a concave approximation to QAP.  However, their ``convex'' relaxation is not convex, which is immediate from noticing that the Hessian is not necessarily positive definite.  \S 4 includes the following quote:
	
	\begin{quote}
		Moreover, although the objective function $- tr(B\T PAP\T)$ is quadratic, it is not necessarily convex.  This follows from computing the Hessian of the objective function with respect to $P$:
		\begin{align}
			\nabla_P^2  =  B \otimes A + B\T \otimes A\T,
		\end{align}
		which is not necessarily positive definite ($\otimes$ indicates the Kronecker product).
\end{quote}

	\item \textbf{See similar algorithm in ``Many-to-Many Graph Matching: a Continuous Relaxation Approach'' in 2010 (arxiv).}

Thank you for pointing out this reference, as we had not yet seen it.  Indeed, this manuscript which is contemporaneous with ours proposes a similar algorithm to FAQAP.  However, they only consider many-to-one and many-to-many problems. Moreover, our brain-graph matching problem is unique, and motivates the development of algorithms with significantly better scaling rules.  We have modified the \S 7 accordingly:

\begin{quote}
	Second, for many brain-graph matching problems, the number of vertices will not be the same across the brains.  Recent work from [29],[38]  and [39] suggest that extensions in this direction would be both relatively straightforward and effective. 
\end{quote}



	\item \textbf{Anyway in the experiments only 16 tests where done and the analysis was focuses on the number of restarts. The proposed algorithms require 1-100 starts where in 12 of 16 it only requires 1 start (the van der Waerden matrix).}

As mentioned above, the 16 tests performed are identical to the 16 tests performed by the previous state of the art, reference [25] in the original submission.  And those 16 are the same 16 as used in a previous publication testing various approximate algorithms (reference [30] in the new submission).  Moreover, the authors of [30] state that those 16 were chosen because they were ``particularly difficult''.  We have significantly rewritten the text to emphasize that our algorithm fundamentally is initialized in the barycenter of the feasible region.  A secondary point in the new submission remarks that random restarts can yield superior performance, time permitting. 	\S 6.3 elaborates on this in the text:
	
	\begin{quote}
		Specifically, [29] created a path following algorithm (\texttt{PATH}) based on a convex and concave relaxation of QAP. In that manuscript, the authors considered 16 datasets from the QAP benchmark, the same 16 datasets as were used in [30], which are known to be ``particularly difficult''. 
	\end{quote}



	\item \textbf{No comments on the recently embedding methods for graph matching: see for instance: ``Graph matching through entropic manifold alignment. CVPR 2011''.
Indeed only same-size graphs seem to be explored.}


Thank you for pointing out this omission, we have rectified the text to refer to this work as mentioned above.

\end{itemize}

% section reviewer_2 (end)














\end{document}
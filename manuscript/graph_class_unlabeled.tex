
\documentclass[10pt,journal,cspaper,compsoc]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[12pt,journal,compsoc]{../sty/IEEEtran}

\usepackage{fixltx2e}
% \usepackage{stfloats}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{cite}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{url}
\input{/Users/jovo/Research/latex/latex_commands.tex}
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

\title{Latent Labeled Graph Classification}

\author{Joshua T.~Vogelstein, John C.~Conroy, Lou Podrazik, Steve Kratzer, Glen A.~Coppersmith, Mark Dredze, 
		% William~R.~Gray,
        R.~Jacob~Vogelstein,
        and~Carey~E.~Priebe% <-this % stops a space
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem J.T. Vogelstein and C.E. Priebe are with the Department
of Applied Mathematics and Statistics, Johns Hopkins University, Baltimore, MD 21218.\protect\\
% note need leading \protect in front of \\ to get a newline within \thanks as
% \\ is fragile and will error, could use \hfil\break instead.
E-mail: joshuav@jhu.edu
\IEEEcompsocthanksitem R.J. Vogelstein is with the Johns Hopkins University Applied Physics Laboratory, Laurel, MD, 20723.}% <-this % stops a space
\thanks{}}
 
% The paper headers
\markboth{IN PREP}%
{Graph Classification}

\IEEEcompsoctitleabstractindextext{%
\begin{abstract}
	Because graphs can encode more information in their structure than vectors, they are becoming increasingly popular data structures for representing information.  While the last century has witnessed the development of a plethora of statistical tools for the analysis of data, the vast majority of these tools natively operate in vector spaces, not graph spaces.  Thus, algorithms for even relatively simple statistical inference tasks, such as two-class classification,  are essentially absent for graph data.  In this work, we propose a number of complementary algorithms to classify graphs, with special attention to the possibility of unknown vertex labels.  Since exactly solving the graph-matching problem is currently computational intractable, we consider several approximate approaches.  We introduce a multiple-restart Frank-Wolfe approach to solving the graph matching problem by formulating it as a quadratic assignment problem.  Although this approach has superior performance than previous state-of-the-art approaches to the graph matching problem, even when it ``should'' do well in classification problems, it is outperformed by a graph invariant strategy.  This is just the beginning. 
\end{abstract}

% Note that keywords are not normally used for peer review papers.
\begin{keywords}
statistical inference, graph theory, network theory, structural pattern recognition, connectome.
\end{keywords}}


% make the title area
\maketitle
\IEEEdisplaynotcompsoctitleabstractindextext
\IEEEpeerreviewmaketitle



\section{Introduction}

\IEEEPARstart{T}{he} statistical analysis of collections of graphs is becoming an increasingly popular desideratum \cite{Bunke2011}.  Specifically, we consider the following idealized scenario. Let $\GG: \Omega \mapsto \mc{G}$ be a graph-valued random variable taking values $G\in \mc{G}$.  Let $Y$ be a categorical random variable, $Y: \Omega \mapsto \mc{Y} \subseteq \mathbb{Z}$, such that each graph has an associated class.  Given a collection of graphs and classes,  we assume they were jointly sampled independently and identically from some true but unknown joint distribution, $\{(\GG_i,Y_i)\}_{i \in [n]} \iid F_{\GG,Y}(\cdot; \bth)$, where $\bth$ is a set of parameters.  Note that $F_{\GG,Y}(\cdot; \bth)$ is but one of a (possibly infinite) set of distributions, collectively comprising the model: $\mc{F_{\GG,Y}}=\{F_{\GG,Y}(\cdot; \bth) : \bth \in \bTh\}$, where $\bTh$ is the set of feasible parameters.  The goal of such an analysis is to learn about the relationship between the random variables $\GG$ and $Y$.   Most standard classification techniques fail in this domain as they typically require classifying objects that live in finite dimensional Euclidean space, $\Real^d$, whereas the object of interest here live in graph space, $\mc{G}$ (even finite graphs do not natively live in Euclidean space).  In this work, therefore, we propose novel extensions of several classification algorithms appropriate for the graph domain.



\section{Graph Classification} % (fold)
\label{sec:graph_classification}



The graph classification problem may be stated thusly: given training data $\mc{T}_n=\{(\GG_i,Y_i)\}_{i \in [n]}$, and a new graph, $\GG$, estimate the new graph's corresponding class, $Y$, assuming each graph/class pair was sampled identically and independently from some true but unknown distribution, $\mc{T}_n,(\GG,Y) \iid F_{\GG,Y}(\cdot; \bth)$ .  Given an appropriately defined risk-function, such as misclassification rate, $R_h=\PP[h(\GG) \neq Y]$, one can then search for the function $h^* \in \mc{H}$ that minimizes the risk function of interest:
\begin{align}
	h^* = \argmin_{h \in \mc{H}} \PP[h(\GG) \neq Y].
\end{align}
In general, $h^*$ is unavailable and dependent on the true but unknown distribution,  $F=F_{\GG,Y}$ (which includes the vertex labels).  When $h^*$ is unavailable, one can utilize training data, $\mc{T}_n$, to obtain $\mh{h}$, an approximation to $h^*$:
\begin{align}
	\mh{h} \approx \argmin_{h \in \mc{H}} \PP[h(\GG) \neq Y | \mc{T}_n],
\end{align}
where $\approx$ indicates that in general, we will not be able to find the actual minimum in the set $\mc{H}$. Regardless, any approach necessarily estimates a decision boundary in the space of graphs separating them into two classes.  %We consider a few distinct such approaches to constructing such a decision boundary:

% \subsection{Graph dissimilarity based approach approach} % (fold)
% \label{sub:_k__n_nearest_neighbor_approach}

% \subsection{Graph dissimilarity based approach approach} % (fold)
% \label{sub:_k__n_nearest_neighbor_approach}


% % section graph_classification (end)
\section{Models}

Let a graph be a 4-tuple consisting of a set of (i) vertices  (ii) edges, (iii) vertex labels, and (iv)  edge attributes. %, such that $\GG=(\VV,\EE,\LL,\Aa): \Omega \mapsto \mc{G}=(\mc{V},\mc{E},\mc{L},\mc{A})$.  Therefore, one can expand the joint distribution: $F_{\GG,Y}=F_{\VV,\EE,\LL,\Aa, Y}$.  
Assume that each graph has the same set of vertices.  Moreover, assume that edge attributes can be represented as scalar quantities, so the edges and edge attributes of a random graph are jointly encoded in an adjacency matrix representation.  Thus, the joint distribution on graphs and classes can be expanded and factorized:
\begin{align} \label{eq:gc}
	F_{\GG,Y}=F_{\LL,\Aa,Y}=F_{\LL,\Aa | Y} F_{Y}
\end{align}
where $\LL: \Omega \mapsto \mc{L} \subseteq \{L_1,L_2,\ldots,L_{n_v}\}=[L_{n_v}]$ is a random vertex labeling,  $\Aa: \Omega \mapsto \mc{A} \subseteq \Real^{n_v \times n_v}$ is a random adjacency matrix, and $n_v$ is the number of vertices in the graphs.  The class-conditional signal therefore derives from two possible sources of variability, $\LL$ and $\Aa$.  \emph{Labeled} graph classifiers therefore proceed accordingly, using the labels to facilitate classification (see \cite{Vogelstein2011}). \emph{Unlabeled} graph classifiers, however, assume that the labels carry no class-conditional signal, that is, they assume that $F_{\LL,\Aa | Y}=F_{\Aa | Y}$. In \emph{Latent labeled} graph classifiers, those under investigation here, the labels are not observed, yet they are not assumed to be wholly uninformative with respect to the task at hand.  


Let $h_{\Aa}^*: \mc{A} \mapsto \mc{Y}$ be the \emph{edge attribute only} Bayes optimal classifier, and $R_{\Aa}^*$ be the risk associated with this classifier.  Similarly, let $h_{\LL,\Aa}^*: \mc{A} \times \mc{L} \mapsto \mc{Y}$ be the edge attribute and vertex label Bayes optimal classifier, and let $R_{\LL,\Aa}^*$ be its risk.  We are interested in parsing model space into those models for which $R_{\LL,\Aa}^* < R_{\Aa}^*$.  A vertices are \emph{stochastically equivalent} whenever



% 
% \subsection{Labeled Graph Classification} % (fold)
% \label{sub:labeled_graph_classification}
% 
% In \emph{labeled} graph classification, we assume that $(\LL,\Aa,Y), \{(\LL_i,\Aa_i,Y_i)\}_{i \in [n]} \iid F_{\LL,\Aa,Y}$, and that we do not observe $Y$. An example of such a scenario is MR connectome classification, where the vertices correspond to macro-neuroanatomical regions, such as the visual cortex.   Because it is relatively easy to draw reasonable boundaries between regions, these inferred graphs have labeled vertices. And because the vertex labels of each graph are observed, we can compare adjacency matrices directly, and use graph classification techniques, such as those described in \cite{Vogelstein2011}.  This facilitates factorizing the likelihood term of Eq. \eqref{eq:gc}:  $F_{\LL,\Aa|Y}=F_{\Aa | \LL, Y} F_{\LL|Y} = F_{\Aa | \LL, Y}$.  Note that although adjacency matrices can be represented by objects in $\Real^{n_v \times n_v}$, the graphs are \emph{not} in finite Euclidean space; rather, the structure of the adjacency matrix may encode information.  In other words, simply vectorizing the adjacency matrix, and performing some standard classification techniques, might be discarding class-conditional signal.  A labeled graph classifier therefore maps from the joint vertex label and edge attribute space into the class space: $h_{\LL,\Aa}: \mc{L} \times \mc{A} \mapsto \mc{Y}$.
% 
% % subsection labeled_graph_classification (end)
% 
% \subsection{Unlabeled Graph Classification} % (fold)
% \label{sub:unlabeled_graph_classification}
% 
% In \emph{unlabeled} graph classification, the labels are assumed to be unknown or uninformative with regard to our inference task; that is, no class-conditional signal is available from the labels. In this context, the likelihood term of Eq. \eqref{eq:gc} factorizes: $F_{\LL,\Aa|Y}=F_{\Aa | Y}$.  A common scenario in which this assumption is made is in classifying chemical compounds, where only graph structure is used \cite{Bunke2011}.  In this context we effectively assume that we have $(\Aa,Y), \{(\Aa_i,Y_i)\}_{i \in [n]} \iid F_{\Aa,Y}$, but we have not observed $Y$, the class of the as yet unclassified unlabeled graph.  Here, any arbitrary permutation of each of the adjacency matrices is equivalent to any other.  Letting $Q \in \mc{Q}$ be a permutation matrix, pre and post-multiplying an adjacency matrix by a permutation matrix yields another adjacency matrix representation, $\mt{A}=QAQ\T$.  Thus, in the unlabeled graph classification setting, each graph implies a quotient space,  $G=\{QAQ\T : Q \in \mc{Q}\}$. An unlabeled graph classifier therefore maps from this quotient space, which is just the edge attribute space, into the class space: $h_{\Aa}: \mc{A} \mapsto \mc{Y}$.
% 
% 
% % subsection unlabeled_graph_classification (end)
% 
% 
% 
% \subsection{Latent-Labeled Graph Classification} % (fold)
% \label{sub:latent_labeled_graph_classification}
% 
% In \emph{latent-labeled} graph classification the labels are latent.   In this context, the likelihood term of Eq. \eqref{eq:gc} does not necessarily factorize. %Moreover, we observe $\Aa, \{(\Aa_i,Y_i)\}_{i \in [n]} \iid F_{\LL, \Aa,Y}$, and we desire to know $Y$, the class of the as yet unclassified unlabeled graph, and we have not observed any labels, although they may contain class-conditional signal (they may not).  
% 
Given such a scenario, one could consider at least three complementary approaches: (i) a graph \emph{labeling} approach in which one effectively tries to estimate labels, or (ii) a graph \emph{invariant} approach in which one does not, and (iii) a graph \emph{dissimilarity} approach in which one could.
% %  %Try to impute the missing labels, and use a labeled graph classifier, $h_{\LL,\Aa}$.
% % 	\item a graph invariant approach. % Ignore the missing labels, and use an unlabeled graph classifier, $h_{\Aa}$.
% % \end{enumerate}
The preferred approach will depend on the assumed model, the data, and the computational resources. Section \ref{sec:algs} provides details for these strategies, and Section \ref{sec:results} provides some guidance with regard to when to use each.





% subsection latent_labeled_graph_classification (end)


% \subsection{Older} % (fold)
% \label{sub:older}
% 
% % subsection older (end)
% 
% In certain graph classification problems the vertex labels are unknown.  In other words, instead of observing $(\mc{V},\mc{E},\mc{L},\mc{A})$ for each graph, we only observe the triple, $(\mc{V},\mc{E},\mc{A})$, which we refer to as an \emph{unlabeled graph}.  In such scenarios, one is essentially faced with a graph isomorphism problem, which can be approached in at least two ways.  First, one could try to \emph{graph match}, that is, find a common set of labels for the vertices of the graphs, so that the graphs have the same adjacency matrix. Second, one can project the graphs into a quotient space that is invariant to the labels.  This can be a negative check for isomorphisms: if a set of graphs have different representations in the quotient space, then they are not isomorphic to one another.  We consider both approaches as possible subroutines as part of a classification function.


% \section{Methods} % (fold)
% \label{sec:methods}


\section{Latent labeled Graph Classifiers} % (fold)
\label{sec:algs}

\subsection{Graph Labeling Classifiers} % (fold)
\label{sec:quadratic_assignment_problem}

We define a graph labeling function as any algorithm that assigns a label to each vertex of a graph: $Q_n: \mc{A}, \Xi^n \mapsto \mc{L}$, where $\Xi \subseteq \mc{G}$, for example, $\Xi=\mc{A}$ (note that we have actually defined a sequence of graph labeling functions).  Remember that we have defined $\mc{L}$ as a subset of $[n_v]$, so each vertex need not have a unique label.  

To use a graph labeling classifier, by definition, one first explicitly attempts to estimate the labels of each vertex in each graph.  Given these label estimates, one can plug them in and apply a labeled graph classifier, $h_{\mh{\LL},\Aa}$, such as those proposed in \cite{Vogelstein2011} (although perhaps keeping the label uncertainty could help).  We therefore proceed by providing a novel approach to solving the graph labeling problem, followed by some options of how one might use them in a labeled graph classifier.

\subsubsection{Graph Labeling} % (fold)
\label{ssub:graph_matching}

A common approach to (approximately) solving the graph labeling problem follows from an adjacency matrix representation of the graph.  A labeled graph can be represented by its adjacency matrix, $A$, whenever its edge attributes are univariate.  Unlabeled graphs, on the other hand, can be represented by a set of adjacency matrices, $\{QAQ\T : Q \in \mc{Q}\}$, where $Q$ is any permutation matrix. Thus, one can define a graph labeling function that finds a permutation matrix that permutes the rows and columns of one graph to match another: % $\sigma_1: \mc{A} \times \mc{A} \mapsto \mc{L}$.    
% More specifically, we consider the % Given a pair of unlabeled graphs, determining whether they are isomorphic with respect to one another is equivalent to determining whether one can find an adjacency matrix of one graph that is identical to the other's.  This problem can be cast as a 
% \emph{quadratic assignment problem} (QAP):
 \begin{align} \label{eq:QAP}
	Q_{QAP} \defeq Q_{QAP}(A,B)= \argmin_{Q \in \mc{Q}} \norm{Q A Q\T - B}^2_F,
\end{align}
where the permutation matrix $Q_{QAP}$ induces a labeling of the vertices of $A$ onto those of $B$. A bit of linear algebra simplifies Eq. \eqref{eq:QAP}: % \cite{Horn1990}, and demonstrates that the above objective function 
%shows that Eq \eqref{eq:QAP} can be simplified:
\begin{multline} \label{eq:qap}
	\argmin_{Q \in \mc{Q}} \norm{Q A Q\T - B}^2_F \\
	= \argmin_{Q \in \mc{Q}} - tr(B\T QAQ\T) - tr(QAQ\T B),			
\end{multline}
which is equivalent to the standard representation of the quadratic assignment problem (QAP) \cite{Conte2004}:
\begin{align}
	\mh{\sigma}= \argmin_{\sigma} a_{\sigma(i), \sigma(j)} b_{ij} = \argmin_{q \in \mc{Q}} q_{ij} a_{ij}, q_{ji} b_{ij}
\end{align}
where $\sigma$ is a permutation function, $\sigma: [n] \mapsto [n]$.  Unfortunately, Eq. \eqref{eq:QAP} is an NP-complete problem \cite{Garey1979a}. The primary difficulty in solving Eq. \eqref{eq:QAP} is the discrete non-convex constraint set.  Thus, it is natural to consider an approximation with the constraints relaxed.  Since the convex hull of permutation matrices is the set of doubly stochastic matrices, we define the approximate quadratic assignment problem:
\begin{align} \label{eq:tqap}
	Q_{AQAP} \defeq Q_{AQAP}(A,B) = \argmin_{Q \in \mc{D}} \norm{Q A Q\T - B}^2_F,
\end{align}
where $\mc{D}$ is the set of doubly stochastic matrices.  When the permutation matrix constraint is relaxed, the equivalence relation shown in Eq. \eqref{eq:qap} no longer holds.  Nonetheless, we proceed by attempting to solve:
\begin{align} \label{eq:nqap}
	\mh{Q}_{AQAP} \approx \argmin_{Q \in \mc{D}} - tr(B\T QAQ\T) - tr(QAQ\T B),
\end{align}
considering it an auxiliary function for which we can compute gradients and ascend a likelihood, unlike the permutation constrained case.  

The Frank-Wolfe (FW) algorithm is a successive linear programming algorithm for nonlinear programming problems; specifically, for quadratic problems with linear (equality and/or inequality) constraints. Let $f(Q)=- tr(B\T QAQ\T) - tr(QAQ\T B)$.  With each iteration $j$, the FW algorithm takes the following steps:

\textbf{Step 1: Compute the gradient} The gradient of $f$ with respect to $Q$ is given by:
\begin{align} \label{eq:grad}
	\nabla_Q^{(j)} = \partial f / \partial Q^{(j)} =  A Q^{(j)} B\T + A\T Q^{(j)} B.
\end{align}

% paragraph step_1_computing_the_gradient (end)

\textbf{Step 2: Find the closest doubly stochastic matrix} Instead of directly descending this gradient, we search for the direction of the doubly stochastic matrix closest to this gradient. Noting that that direction may be computed by the dot-product operator, we have:
\begin{align}\label{eq:dir}
	W^{(j)} = \argmin_{W^{(j)} \in \mc{D}} \langle W^{(j)}, \nabla_Q^{(j)} \rangle. %  \sum_{i,j=1}^m 	\left( 	\nabla_Q^{(j)}\circ W^{(j)} \right)_{ij}.
\end{align}
Eq. \eqref{eq:dir} can be solved as a Linear Assignment Problem (LAP).  More specifically, a LAP can be written as:
\begin{align} \label{eq:LAP}
	Q_{\text{LAP}} \defeq Q_{\text{LAP}}(A,B) = \argmin_{Q \in \mc{Q}} \norm{QA - B }^2_F,
\end{align}
which, when $B=I$, can be simplified:
\begin{align} \label{eq:proja}
	Q_{\text{LAP}}(A,I) &=\argmin_{Q \in \mc{Q}} \norm{QA - I}_F^2 
	\nonumber \\ &= \argmin_{Q \in \mc{Q}} (QA-I)\T (QA-I) 
	\nonumber\\ &=\argmin_{Q \in \mc{Q}} A\T Q\T QA -2QA - II 
	\nonumber\\ &= \argmin_{Q \in \mc{Q}}  -\langle Q, A \rangle.  
\end{align}
In other words, letting $B=I$, the projection of a matrix onto its nearest doubly stochastic matrix is a LAP problem.  While Eq. \eqref{eq:proja} cannot be solved directly, as above, we can relax the permutation matrix constraint to the doubly stochastic matrix constraint:
\begin{align}\label{eq:relaxed}
	Q_{\text{LAP}}(A,I) = \argmin_{Q\in\mc{D}} -\langle Q, A \rangle. 
\end{align}
Since the permutation matrices are the vertices of the set of doubly stochastic matrices, finding the minimum of Eq. \eqref{eq:relaxed} is guaranteed to yield a permutation matrix (as minima are necessarily at the vertices).  Thus, letting $A=\nabla_Q^{(j)}$, solving Eq. \eqref{eq:relaxed}---which is a linear problem with linear and non-negative constraints---is equivalent to solving Eq. \eqref{eq:dir}.  Fortunately, the Hungarian algorithm solves any LAP in $\mc{O}(n^3)$ \cite{Burkard2009}, thus this projection is relatively computationally efficient.\footnote{More efficient algorithms are available for certain special cases, that is, whenever the matrix-vector multiplication operation is fast (for example, when both $A$ and $B$ are sparse).}
% paragraph step_2_finding_the_closest_doubly_stochastic_matrix (end)

\textbf{Step 3: Update the direction} Given $W^{(j)}$, the new direction is given by:
\begin{align}
	d^{(j)}=W^{(j)}-Q^{(j)}.
\end{align}

% paragraph step_3_updating_the_direction (end)

\textbf{Step 4: Line search} Given this direction, one can then perform a line search to find the doubly stochastic matrix that minimizes the objective function along that direction:
\begin{align}
	\alpha^{(j)} = \argmin_{\alpha \in [0,1]} f(Q^{(j)} + \alpha^{(j)} d^{(j)}).
\end{align}
This can be performed exactly, because $f$ is a quadratic function.  

% paragraph step_4_line_search (end)

\textbf{Step 5: Update $Q$} Finally, the new estimated doubly stochastic matrix is given by:
\begin{align}\label{eq:update}
	Q^{(j+1)} = Q^{(j)} + \alpha^{(j)} d^{(j)}.
\end{align}

% paragraph step_5_update_q_ (end)

\textbf{The grand finale} Steps 1--5 are iterated until convergence, computational budget limits, or some other stopping criterion is met.  These 5 steps collective comprise the FW algorithm.  Note that while $Q^{(j)}$ will generally not be a permutation matrix, we do not project $Q^{(j)}$ back onto the set of permutation matrices between each iteration, as that projection requires $\mc{O}(n^3)$ time. After the final iteration, however, we have $\mh{Q}_{AQAP}$, which we project onto the set of permutation matrices:
\begin{align} \label{eq:proj}
	\mh{Q}_{QAP} = \argmin_{Q \in \mc{Q}} \langle \mh{Q}_{AQAP}, Q \rangle,
\end{align}
which is a LAP, and yields an approximate solution to QAP.  Let FW appended with a projection onto the permutation matrices be denoted by \texttt{QAP}.

% paragraph the_final_iteration (end)

\textbf{Multiple restarts} Note that FW will not generally achieve the global optimum even of Eq. \eqref{eq:tqap}, because $f$ is not necessarily positive definite.  This is clear upon computing the Hessian of $f$  with respect to $Q$:
\begin{align}
	\nabla_Q^2  =  B \otimes A + B\T \otimes A\T,
\end{align}
where $\otimes$ indicates the Kronecker product. This means that the initialization, $Q^{(0)}$, could be important.  While any doubly stochastic matrix would be a feasible initial point, two choices seem natural: (i) the ``flat doubly  stochastic matrix,'' $J=\ve{1}\T \ve{1}/n_v$, which is the middle of the feasible region, and (ii) the identity matrix, which is a permutation matrix.  Therefore, if we run \qap  once, we always start with one of those two.  If we use multiple restarts, each initial point is ``near'' the flat matrix.  Specifically, we sample $J'$, a random doubly stochastic matrix using 10 iterations of Sinkhorn balancing \cite{Sinkhorn1964}, and let $Q^{(0)}=(J+J')/2$.  We refer to multiple re-starts of \qap with subscripts, that is, the performance of \qapn is the best result of $n$ pseudo-random re-starts of \texttt{QAP}.  Note that \qap natively operates on matrices, which could correspond to either weighted or unweighted graphs.

% paragraph putting_it_all_together (end)
% subsubsection graph_matching (end)


\subsubsection{Using the estimated vertex labels} % (fold)
\label{sec:algorithms}

Given the above strategy to (approximately) solve the graph labeling problem, one can represent the graphs as adjacency matrices, and use many possible possible classifiers, some of which designed specifically for the labeled graph domain \cite{Vogelstein2011}. We focus here on a graph model based strategy, while acknowledging other possibilities below.  


% \textbf{A graph model approach: \texttt{BPI}$\circ$\qap} % (fold) \label{ssub:bayes_plug-in_circ_qap}

A labeled graph classification model based strategy begins by defining a model for the data. For example, \cite{Vogelstein2011} define an independent edge graph classification model, $\mc{F}_{\LL,\Aa,Y}=\{F_{\LL,\Aa,Y}(\cdot; \bth) : \bth \in \bTh \}$, where $F_{\LL,\Aa,Y}$ can be factorized,  $F_{\LL,\Aa, Y } = F_{\LL,\Aa | Y} F_{Y}$. The likelihood can be further expanded,%: 
%\begin{align}
	$F_{\LL,\Aa| Y }(\cdot; \bth) =\prod_{(u,v) \in \mc{E}}\text{Bern}(a_{uv}; p_{uv|y})$,
%\end{align}
where $\mc{E}$ is the set of edges, $a_{uv}$ is the value of the edge from the vertex labeled $v$ to the vertex labeled $u$, and $p_{uv|Y}$ is the probability of an edge from $v$ to $u$ in class $y$.  A Bayes plug-in classifier proceeds by estimating the parameters, $\mb{p}=\{p_{uv|y}\}, \mb{\pi}=\{\pi_y\}$, and plugging them into the Bayes classifier:
\begin{align} \label{eq:bpi}
	\mh{y} = \argmax_{y \in \mc{Y}} \prod_{(u,v) \in \mc{E}}\text{Bern}(a_{uv}; \mh{p}_{uv|y})  \mh{\pi}_y.
\end{align}
When the labels are latent, the extension of the Bayes plug-in classifier also plugs-in the estimated vertex labels. %:
% \begin{align} \ label{eq:bpi}
% 	\mh{y} = \argmax_{y \in \mc{Y}} \prod_{(u,v) \in \mc{E}}\text{Bern}(a_{\mh{u}\mh{v}}; \mh{p}_{uv|y}) \mh{\pi}_y.
% \end{align}
Therefore, to use a Bayes plug-in classifier, given a model, one can take the following steps.  First, obtain $s$ ``prototpye'' graphs that will be \texttt{QAP}ed to, and assign each training graph, $A_i$, to a prototype, $A_{i*}$  (see Section \ref{sec:results} for details on the caveats of the various ways of choosing prototypes).  Second, \qap each graph to its corresponding prototype:  $\mh{Q}_i=\mh{Q}_{QAP}(A_i,A_{i*})$, yielding $\mh{A}_i=\mh{Q}_i A_i \mh{Q}_i\T$.  Third, estimate the parameters of the model by plugging-in the vertex labels.  For instance, one can obtain the maximum likelihood estimators:
\begin{align}
	\{\mh{\mb{p}},\mh{\mb{\pi}}\} = \argmax_{\mb{p},\mb{\pi}} \prod_{i \in [n] | y } p_{uv|y}^{a_{\mh{u}\mh{v}}^{(i)}}(1-p_{uv|y})^{1-a_{\mh{u}\mh{v}}^{(i)}} \pi_y,
\end{align}
where $a_{\mh{u},\mh{v}}^{(i)}$ comprise the vertex-label pluggin-in adjacency matrix, $\mh{A}_i$. Finally, one can then plug the estimates into a Bayes classifier, Eq. \eqref{eq:bpi}.  Call this algorithm \texttt{BPI} $\circ$ \texttt{QAP}.


% First, align each graph in each class to its class prototype using \texttt{QAP}$_n$.  Second, assume a  model,   Third, given such a factorization, one could then, for instance, estimate $\{\bth,\pi\}$ and then use standard model-based classifiers, such as the Bayes plug-in (BPI) classifier.   Fourth, the test graph can then be \texttt{QAP}ed to the prototype of each class.  Fourth, compute the posterior probability of the test graph coming from each class, by plugging in the parameters to the Bayes classifier.  Finally, let the estimated class be the \emph{maximum a posteriori} class.  


\subsection{Graph Invariant Classifiers} % (fold)
\label{sub:graph_invariants}

A graph invariant (GI) is any function that maps a graph to a scalar whose value is independent of the vertex labels, $T: (\mc{V},\mc{E},\mc{A}) \mapsto \Real$.  By defining a set of GIs, one can embed a collection of graphs into a quotient space invariant to vertex labels.  Whenever this quotient space is a subset of finite dimensional Euclidean space, all standard machine learning classifiers may be implemented to solve the classification problem.  


To use graph invariants to classify, one first must choose as set of graph invariants.  Unfortunately, there is no known set of graph invariants that are collectively optimal for graph classification models. Fortunately, some recent theoretical work shows that certain graph invariants have greater discriminability with regard to certain graph inference tasks \cite{Ruhkhin2011}. With that in mind, we consider the following invariants described fully in \cite{CPP11}:
% generalize a standard set of unweighted graph invariants---described fully in \cite{CPP11}---developing their weighted graph invariant counterparts. We describe each briefly:
\begin{itemize}
	\item $T_{weight}$: total weight of all the edges in the graph
	\item $T_{maxweight}$, is the max over $d(v)$ for all $v \in \mc{V}$, where $d(v)$ is the sum of all weights incident to vertex $v$	
	\item $T_{MAW_g}$: a greedy approximation of the maximum average weight (MAW), akin to maximum average degree
	\item $T_{MAW_e}$: an eigenvalue approximation of MAW
	\item $T_{wS_1}$: the maximum weighted locality statistic, akin to the typical scan statistic, but sums the weight of edges in each neighborhood rather than just the number of edges.
	\item $T_{Dijkstra}$: the average Dijkstra path distance between each pair of vertices
	% \item $T_{size}$ is the number of edges in the graph.
	% \item $T_{maxdegree}$ is the $\max_v d(v)$ for all $v \in \mc{V}$, where $d(v)$ is the degree of vertex $v$.
	% \item $T_{MAD_g}$ is a greedy approximation of the maximum average degree.
	% \item $T_{MAD_e}$ is an eigenvalue approximation of the same.
	% \item $T_{S_1}$ is the maximum locality statistic, as described in \cite{Priebe}.
	% \item $T_{triangles}$ is the number of triangles (paths of length 3) in the graph.
	% \item $T_{cc}$ is the average clustering coefficient.
	% \item $T_{averagepathlength}$, $T_{closeness}$, and $T_{betweenness}$ are all measures of the path lengths required to traverse between arbitrary vertices or edges.
\end{itemize}
For each graph $G_i$ in the training set, we compute a graph invariant vector: $\mb{T}_i: \mc{G} \mapsto \Real^d$.  We stack these $n$ $d$-dimensional vectors to form a matrix $\mb{T} \in \Real^{n \times d}$.  Letting $T_{ij}$ indicate the $i^{th}$ graph invariant of the $j^{th}$ graph, and normalize each element to be between zero and one according to:  $T_{ij} \leftarrow \frac{T_{ij} - \min_i (T_{ij})}{\max_i(T_{ij}) - \min_i(T_{ij})}$.

% We then whiten this matrix to control for the divergence means and scales of the various graph invariants, $\mb{T} \rightarrow \mb{E}\mb{\Lambda}^{-1/2}\mb{E}\T \mb{T}$, where $\mb{E}\mb{\Lambda}\mb{E}\T$ is the eigenvalue decomposition of the covariance matrix,$\EE[\mb{T}\mb{T}\T]$ \cite{Hyvarinen2000}.  
Now, to estimate the class of a test graph, we first compute its invariant vector, $\mb{t}$, and normalize it appropriately.  We then apply a variety of machine learning algorithms, including $k$NN, linear classifiers, and SVMs.  For the below connectome data, the best performing algorithm is the exact confidence weighted classifier \cite{Crammer2008}.  Call this algorithm \texttt{CW}$\circ$\texttt{GI}.


% subsection graph_invariants (end)



% subsubsection bayes_plug-in_circ_qap (end)

% subsection graph_isomorphism_approach (end)


\subsection{Graph dissimilarity Classifiers} % (fold)
\label{sub:graph_dissimilarity_classifiers}


% \textbf{A graph dissimilarity approach: \texttt{$k$NN} $\circ$ \qap} % (fold) \label{ssub:_k_nn_circ_qap}
A \emph{graph dissimilarity} is any non-negative function $\delta: \mc{G} \times \mc{G} \mapsto \Real_+$, typically also satisfying several criteria for being a metric.  %Given an adjacency matrix representation, many such dissimilarities are possible (for example, graph edit distance).  
It is becoming increasingly popular to use a \emph{graph kernel} as the dissimilarity \cite{Bunke2011}.\footnote{A graph kernel is any function $\kappa(G,G')=\langle \phi(G), \phi(G') \rangle$, where $\phi(\cdot)$ maps from graph space to finite dimensional Euclidean space, $\phi: \mc{G} \mapsto \EE^d$.}  Graph kernels have a number of desirable properties, perhaps most notably, that one can then use standard \emph{kernel machines} to classify \cite{Vapnik1998}.	Regardless, given any dissimilarity, one can apply at least two different kinds of classifiers.

% : nearest neighbor style classifiers and interpoint-dissimilarity based classifiers \cite{Duin2011}.  

First, one could implement a nearest neighbor style classifiers, such as the $k_n$ nearest neighbor ($k$NN) classifier.  In addition to being universally consistent\footnote{A sequence of $k$NN classifiers is guaranteed to converge to the Bayes optimal classifier  if  as $n \conv \infty$, $k \conv \infty$ but $k/n \conv 0$ \cite{Devroye1997}.}, $k$NN classifiers are computationally efficient, in that they only require $n+1$ graph dissimilarity computations (assuming a single test graph).  

Alternately, one could implement an interpoint-dissimilarity matrix based algorithm \cite{Duin2011}. This strategy has the advantage of using all available information to generate a class prediction, but a disadvantage that it requires $\binom{n+1}{2}$ graph dissimilarity computations. Moreover, it may be more sensitive to outliers.

For concreteness and simplicity, consider the $k$NN strategy using the \qap objective function as a dissimilarity.  Given a test adjacency matrix, $A$, \qap it to all $\{B_i\}_{i \in [n]}$ training adjacency matrices.  Instead of using the $\argmin$ of the QAP objective function as above, here we use the $\min$ as a dissimilarity, that is, we obtain $d_i=d(\mh{A}_i,B_i)$ for all $i \in [n]$, and sort them: $d_{(1)} \leq d_{(2)} \leq \cdots \leq d_{(n)}$.  Let the $k_n$ nearest neighbors of $A$ be the graphs with the $k_n$ smallest distances, $\{d_{(1)},\ldots, d_{(k_n)}\}$.  The estimated class of the training sample $A$ is then the plurality class of the $k_n$ nearest neighbors: $\mh{y}=\argmax_{y} \II\{\sum_{i \in [k_n]} y_{(i)} = y \}$. Denote this approach by $k$\texttt{NN}$\circ$\texttt{QAP}.

% subsubsection _k_nn_circ_qap (end)



% subsection graph_dissimilarity_classifiers (end)


% section algorithms (end)


\section{Results}
\label{sec:results}


\subsection{Theoretical results} % (fold)
\label{sub:when_to_use_what}



\begin{thm}
	Under the graph-class model, $\mc{F}_{\GG,\YY}$, whenever all vertices are \emph{stochastically equivalent}, $R_{\LL,\Aa}^* = R_{\Aa}^*$.  Otherwise, $R_{\LL,\Aa}^* < R_{\Aa}^*$.
\end{thm} 
\begin{proof}
	Assume without loss of generality that $pi_y=\pi$ for all $y \in \mc{Y}$. Thus, $h_{\Aa}^*$ and $h_{\LL, \Aa}^*$, can be written as follows:
	\begin{align}
		\mh{y}_{\Aa}&=\argmax_{y\in\mc{Y}} F_{\Aa | Y}\\
		\mh{y}_{\LL,\Aa}&=\argmax_{y \in \mc{Y}} F_{\Aa, \LL| Y}
	\end{align}
\end{proof}


\begin{thm}
	Under the graph-class model, $\mc{F}_{\GG,\YY}$, if all the graphs are passed through a vertex shuffle channel, then $R^*_{\LL,\Aa}=R^*_{\Aa}$.
\end{thm}
\begin{proof}
Information processing lemma....
\end{proof}

 Specifically, if one has good reason to believe that the vertex labels lack much class-conditional signal, then one ``should'' ignore them and use a graph invariant approach.  Alternately, if one believes that the vertex labels might contain some class-conditional signal, then one ``could'' try to use them.  However, whether those efforts are fruitful will depend on a bias-variance trade-off.  Certainly, the class-conditional entropy for the joint vertex labels and edge attributes is at least as great as the class-conditional entropy for the edge attributes alone, $\mc{I}(\LL,\Aa | Y) \geq \mc{I}(\Aa | Y)$.   But if the vertex have labels, ignoring them will induce more bias.  

Another view of how to determine whether to try using the labels concerns the relative effective signal-to-noise-ratios.  Specifically, if given the vertex labels, the adjacency matrices are all very similar, then $F_{\Aa | \LL, Y}$ has relatively low entropy.  Therefore, one can try to impute the missing labels with perhaps great success.  Alternately, if $F_{\Aa | \LL, Y}$ has relatively high entropy, then imputing the missing labels might be too difficult, and we are better off using only $F_{\Aa | Y}$.

It is our contention that many interesting graph classification problems can be cast as latent (or noisy) labeled graph classification problems.  For instance, in the MR connectome situation, labels are assigned to vertices using (nonlinear) image registration, which works well, but struggles in certain cases (for example, the boundaries of the regions).  Further, in the chemical compound classification setting, one could perhaps use the vertex labels (each vertex is a specific element), to enhance classification performance.  

The sequel considers these two complementary approaches to solving latent labeled graph classification problems. Via synthetic data analysis, we demonstrate scenarios in which the above intuition regarding the bias-variance trade-off suggests which approach is likely more effective.

\subsubsection{Graph labeling approachs} % (fold)
\label{ssub:graph_labeling_approachs}

% subsubsection graph_labeling_approachs (end)

Which one to use depends on whether we first assume there is a ``canonical labeling.''  A canonical labeling is vertex labeling that introduces a vertex ordering for an equivalence class of graphs (that is, all graphs isomorphic to one another).  In the absence of an assumed canonical labeling, a \emph{graph dissimilarity} approach seems more natural to us.  In the presence of an assumed canonical labeling, a \emph{graph model} approach seems more natural to us.


When a canonical labeling is assumed to exist, we can pursue a complementary strategy. Note that in the graph dissimilarity approach described above, the vertex labels of adjacency matrix $A$ is a pairwise property, $Q^A_i$, which changed for each $B_i$.  When a canonical labeling is assumed, we search a simple permutation matrix, $Q^A$, invariant with respect to all the other training samples.  Sometimes a canonical labeling is somehow known in advance. Alternately, one could choose a set of ``prototype'' graphs (possibly with cardinality one), and graph match all other graphs to that set (one).  While some efforts have been directed at choosing prototypes (see  \cite{Bunke2011}), it remains a bit of a sticky wicket.  Regardless, assuming a canonical labeling (somehow), a graph model approach proceeds as follows.   

Like the above $k$NN strategy, a straightforward implementation of a \emph{graph model} based approach depends on first choosing a particular graph onto which one implements the graph labeling function.  One option would be to label each training graph onto the test graph.  While simple, a disadvantage of this approach is that it might diminish the differences between the two classes.  An alternative strategy would be to choose a ``prototype'' from each class, 

% However, if all the training graphs are unlabeled, unless the class-conditional signal is independent of the vertex labels, one must somehow deal with the absent labels.  Sometimes a ``canonical'' labeling is somehow natural, and can be searched for.  Otherwise, one could \qap all the training graphs to the test graph.  This approach has the unfortunate consequence of making all the training graphs more similar to one another, disregarding the class labels.  Another option would be to select a ``prototype'' from each class. Although several prototype selection strategies have been studied, prototype selection is still problematic \cite{Bunke2011}.  Finally, one could generate prototype for each class, using all available information.  This approach is intriguing but complicated.  Each of these alternatives essentially defines a canonical labeling per class.

% Regardless of how a canonical labeling is chosen per class, given this canonical labeling, a graph model approach takes the following steps.
% subsection when_to_use_what (end)


\subsection{QAP benchmarks vs. PATH algorithm}

We first compare the performance of \qapn with recent state-of-the-art approaches on the QAP benchmark library \cite{Burkard1997}.  Specifically, \cite{Zaslavskiy2009} reported improved performance in all but two cases, in which the QPB method of Cremers et al. \cite{Schellewald2001} achieved a lower minimum.  We compare \qapn with the previous best performing algorithm.  In \emph{all} cases, \texttt{QAP}$_3$ outperforms the previous best result, often by orders of magnitude in terms of relative error. In three cases, \qapb achieves the absolute minimum.  In 12 out of 16 cases, $75\%$, the simple \qapa algorithm outperforms the others (starting with the flat doubly stochastic matrix).  See Figure \ref{fig:fwpath} for quantitative comparisons.


% \begin{table}[h!]
% \caption{Comparison of Frank-Wolfe with Minimum Solution and Previous State-of-the-Art (PSOA)}
% \begin{center}
% \begin{tabular}{|r|r|r||r|r|r|r|r|}
% \hline
% \# & Problem  &   Min    & \qapb & \texttt{QAP}$_{3}$ & \texttt{QAP}$_{2}$ & \qapa & PSOA\\
% \hline
% 1&    chr12c &   11156 &   12176 &   13072 &   13072 &   13072 &   18048\\
% 2&    chr15a &    9896 &    9896 &   17272 &   17272 &   27584 &   19086\\
% 3&    chr15c &    9504 &   10960 &   14274 &   14274 &   17324 &   16206\\
% 4&   chr20b &    2298 &    2786 &    3068 &    3068 &    3068 &    5560\\
% 5&    chr22b &    6194 &    7218 &    7876 &    7876 &    8482 &    8500\\
% 6&    esc16b &     292 &     292 &     294 &     294 &     320 &     296\\
% 7&     rou12 &  235528 &  235528 &  238134 &  253684 &  253684 &  256320\\
% 8&     rou15 &  354210 &  356654 &  371458 &  371458 &  371458 &  381016\\
% 9&     rou20 &  725522 &  730614 &  743884 &  743884 &  743884 &  778284\\
% 10&    tai10a &  135028 &  135828 &  148970 &  157954 &  157954 &  152534\\
% 11&    tai15a &  388214 &  391522 &  397376 &  397376 &  397376 &  419224\\
% 12&    tai17a &  491812 &  496598 &  511574 &  511574 &  529134 &  530978\\
% 13&    tai20a &  703482 &  711840 &  721540 &  721540 &  734276 &  753712\\
% 14&    tai30a & 1818146 & 1844636 & 1890738 & 1894640 & 1894640 & 1903872\\
% 15&    tai35a & 2422002 & 2454292 & 2460940 & 2460940 & 2460940 & 2555110\\
% 16&    tai40a & 3139370 & 3187738 & 3194826 & 3194826 & 3227612 & 3281830\\
%     \hline
% \end{tabular}
% \end{center}
% \label{tab:fwpath}
% \end{table}%

\begin{figure}[htbp]
	\centering			
	\includegraphics[width=1.0\linewidth]{../figs/benchmarks.pdf}
	\caption{\texttt{QAP}$_3$ outperforms PSOA on all 16 benchmark graph matching problems.  Moreover, \qapa outperforms PSOA on 12 of 16 tests.  For 3 of 16 tests, \qapb achieves the minimum (none of the other algorithms ever find the absolute minimum), as indicated by a black dot.  Let $f_*$ be the minimum and $\mh{f}_x$ be the minimum achieved by algorithm $x$.  Error is $f_*/\mh{f}_x-1$.  }
	\label{fig:fwpath}
\end{figure}




\subsection{Unweighted Graph Simulation}

\texttt{QAP}$_n$'s near perfect performance gave us hope for using \qap as part of an unlabeled graph classifier.  To investigate further, we generated some simulations using the following assumptions.  First, assume an independent edge random graph model for each class: $F_y=\prod_{(u,v) \in \mc{E}} F_{uv|y}$.  For this simple graph scenario, each edge is a Bernoulli random variable, $F_{uv|y}=\text{Bern}(a_{uv}; p_{uv|y})$, where $\{p_{uv|y}\}$ are the likelihood parameters.  Then, assume class prior probabilities are equal, $\PP[Y=1]=\PP[Y=0]=1/2$.  For simplicity, we sample one graph from each class, meaning $n=2$, and a single training graph sampled according the class priors. Thus, each simulation is defined by $\mc{M}=(P_0,P_1,n_v)$, where $P_0$ and $P_1$ are the class-conditional likelihoods, and $n_v$ is the number of vertices per graph.  Given a model, $\mc{M}$, we generate $n_{MC}$ Monte Carlo trials.  For each model, $R_{chance}\approx 0.5$, as estimated by using BPI to classify without first implementing \texttt{QAP}.  We estimate Bayes error, $R_*$, by using the true parameters and a Bayes plug-in classifier (that is, we use all the labels).  We then implement \texttt{BPI}$\circ$\texttt{QAP}$_1$, and plot both the misclassification rate and objective function $f(Q^{(j)})$ as a function of iteration number (not number of restarts, which we hold fixed at one). Figure \ref{fig:homo} shows a model (right panel) and results (left panel) of one such simulation. Intriguingly, the first iteration of \qapa seems to basically do the trick.  This led us to investigate the relationship between LAP and QAP.

\begin{figure}[htbp]
	\centering			
	\includegraphics[width=1.0\linewidth]{../figs/homo_kidney_egg_model}
	\includegraphics[width=1.0\linewidth]{../figs/homo_kidney_egg_performance}
	\caption{Homogeneous-kidney-egg model simulation. The left and middle panels show the model parameters for class 0 and 1, respectively.  Each edge in the ``kidney'' in both classes has probability $0.5$; in the egg, class 0 edges are sampled with probability $0.25$, and class 1 edges are sampled with probability $0.75$. The right panel shows the QAP objective function (gray) and misclassification rate (black) as a function of iteration number. LAP does approximately as well as QAP on this (and other) simple graph simulation.  Note that $R_{chance}\approx 0.5$ and $R_* \approx 0$ for this simulation. The units of the right-side ordinate are arbitrary. The QAP objective function evaluation prior to any QAP iterations is beyond the bounds of this figure.}
	\label{fig:homo}
\end{figure}

% described above with $n_v=10$ vertices and $n=1000$ total samples, 500 from each class.  First, we generated a simulated homogeneous-kidney-egg problem, as depicted in Figure \ref{fig:homo_subfig1}.  Then, we run the Bayes plug-in \qapa algorithm described above.  Note that \qapa is an \emph{iterative} algorithm, so we can evaluate the performance of each iteration (not restart). 

% While Fig. \ref{fig:homo_subfig2} shows the QAP objective function decreasing with each iteration, Fig. \ref{fig:homo_subfig3} shows that classification performance does not decrease.  We found similar numerical results in two additional simulations: a heterogeneous-kidney-egg model (Figure \ref{fig:hke}) and a fully heterogeneous model (Figure \ref{fig:hetero}). Note that in all simulations $R_{chance} \geq \mh{R}_{QAP} \geq R_*$, as it must be.  Multiple iterations not improving classification performance led us to investigate the relationship between QAP and the Linear Assignment Problem (LAP).




\subsection{LAP vs. QAP} % (fold)
\label{sub:lap_vs_qap}

Much like the QAP objective function from Eq. \eqref{eq:QAP} can be simplified to Eq. \eqref{eq:qap}, the LAP objective function can be similarly simplified:
\begin{align}
	\argmin_{Q \in \mc{Q}} \norm{QA-B}_F^2 = \argmin_{Q \in \mc{Q}} tr(QA B\T).
\end{align}
Letting $f_{LAP}(Q)=tr(QA B\T)$, the gradient is:
\begin{align}
	% f_{QAP}(Q)	&= -tr(B\T QAQ\T) -tr(QAQ\T B)  &f_{LAP}(Q)&=-tr(AQ\T B\T) \\
	% \nabla_{QAP}&= AQB\T+A\T QB               	&
	\nabla_{LAP}&=2A B\T.
\end{align}
% Thus, when $Q=I$, the gradient of the QAP objective function is identical to that of the LAP objective function. Thus, one can use gradient ascent to to solve a LAP.  The gradient of $f'(Q)=\norm{AQ\T-B}_F^2$ is %:
% % \begin{align} \label{eq:grad2}
% 	$\partial f'/\partial Q = 2A B\T$. 
% % \end{align}
Comparing this gradient to that of QAP---Eq. \eqref{eq:grad}---one can see that when $Q^{(j)}$ is the identity matrix, the two gradients are identical.  Thus, if QAP is initialized at the identity matrix, the first permutation matrix---output of Step 2---is identical to $\mh{Q}_{LAP}$; although the line search will make $Q^{(1)} \neq \mh{Q}_{LAP}$, in general.  %Moreoever, projecting a matrix onto the closest permutation matrix can be written as a LAP because of the following relationship:
% \begin{align}
% 	\argmin_{Q \in \mc{Q}} \norm{QA\T - I}_F^2 &= \argmin_{Q \in \mc{Q}} (QA\T-I)\T (QA\T-I) 
% \nonumber\\ &=\argmin_{Q \in \mc{Q}} AQ\T QA\T -2QA\T - II = \argmin_{Q \in \mc{Q}}  -\langle Q, A\T \rangle  
% \end{align}
In the above simulation, the first iteration of \qap is essentially the only useful one.  Thus, we compare the performance of \texttt{BPI}$\circ$\texttt{LAP} (dark gray).  The performance of LAP and QAP are not statistically different for this simulation.  This suggests that for certain problems, LAP (which is $\mc{O}(n^3)$) is both an efficient and useful approximation to solving NP-hard graph matching problems. We were unable to find a model for simple graphs in which multiple iterations of \qap improved performance over LAP. %We confirm this intuition by substituting QAP with LAP in the above simulations (black line).  As depicted in the above figures, this intuition is consistent with the numerical results. In other words, while naively one might implement an algorithm with exponential time complexity, LAP, which is only quadratic time complexity, will often suffice.


% subsection lap_vs_qap (end)


\subsection{Weighted simulation} % (fold)
\label{sub:heterogeneous_simulation}

Because \qapa works for both weighted and unweighted, we next simulated multi-graphs (that is, integer valued weights).  The below simulation is identical to the above except for $F_{uv|y}$---the edge random variable---was Bernoulli before and is now Poisson:  $F_{uv|y}=\text{Poisson}(a_{uv}; \lambda_{uv|y})$.  Figure \ref{fig:poiss} shows misclassification rate steadily decreasing with each iteration.

\begin{figure}[htbp]
	\centering			
	\includegraphics[width=1.0\linewidth]{../figs/poiss_model}
	\includegraphics[width=1.0\linewidth]{../figs/poiss_performance}
	\caption{Multigraph model simulation. The left and middle panels show the parameters for class 0 and  1, respectively.  The right panel shows the QAP objective function (gray) and misclassification rate (black) as a function of iteration number; both clearly descending.  For comparison, both $\mh{R}_{LAP}$ and $\mh{R}_*$ are shown.    }
	\label{fig:poiss}
\end{figure}

% subsection heterogeneous_simulation (end)


% \begin{figure}[ht]
% \centering
% \subfigure[model]{
% \includegraphics[scale=0.4]{../figs/hetero_kidney_egg_model}
% \label{fig:hke_subfig1}
% }
% \subfigure[objective function]{
% \includegraphics[scale=0.4]{../figs/hetero_kidney_egg_obj}
% \label{fig:hke_subfig2}
% }
% \subfigure[Lhat +/- Lstd]{
% \includegraphics[scale=1]{../figs/hetero_kidney_egg_Lhats}
% \label{fig:hke_subfig3}
% }
% \label{fig:hke}
% \caption{hetero kidney egg model}
% \end{figure}


\subsection{Connectome Classification} % (fold)
\label{sub:connectome_classification}

A ``connectome'' is a graph in which vertices correspond to biological neural units, and edges correspond to connections between the units.  Diffusion Magnetic Resonance (MR) Imaging and related technologies are making the acquisition of MR connectomes routine \cite{Hagmann2010}.  We use 49 subjects from the Baltimore Longitudinal Study on Aging, with acquisition and connectome inference details as reported in \cite{OHBM10}.  For each connectome, we obtain a $70 \times 70$ element adjacency matrix, where each element of the matrix encodes the number of streamlines between a pair of regions, ranging between 0 and about 65,000.  Associated with each graph is class label based on the gender of the individual (24 males, 25 females).  Because the vertices are labeled, we can compare the results of having the labels and not having the labels.  As such, we implement the following classification strategies.  In each case, we use a leave-one-out strategy to evaluate performance:

\begin{description}
	\item[\texttt{N/A-QAP}] Using the vertex labels, implement a standard $1$NN classifier, where distance is the norm of the difference between any pair of adjacency matrices.
	\item[\texttt{1-QAP}] Permute only the vertex labels of the test graph, and then implement \texttt{$1$NN$\circ$\qapa}.
	\item[\texttt{48-QAP}] Permuting the vertex labels, then implement \texttt{$1$NN$\circ$\qapa}.
	\item[\texttt{AVG-QAP}] Permuting the vertex labels, \qapa each of the 48 training graphs to the test graph.  Then, given those permuted adjacency matrices, compute the average, and then implement a standard $1$NN classifier.
	\item[\texttt{1NN-GI}] Use the graph invariant approach as described above. We provide the normalized graph invariants as inputs into a number of standard classifiers, including $k$NN, linear classifiers, support vector machines, random forests, and CW. On this data, the CW classifier performed best; we therefore only report its results.
\end{description}

Table \ref{tab:connectome} shows leave-one-out misclassification rates for the various strategies.


\begin{table}[h!]
\caption{MR Connectome Leave-One-Out Misclassification Rates}
\begin{center}
\begin{tabular}{|r|r|r|r|r|}
\hline
\texttt{N/A-QAP} & \texttt{1-QAP} & \texttt{48-QAP} & \texttt{AVG-QAP} & \texttt{1NN-GI}\\
\hline
$20\%$ & $31\%$ & $45\%$ & ?? & $25\%$ \\
    \hline
\end{tabular}
\end{center}
\label{tab:connectome}
\end{table}%


\section{Discussion}


In this work, we have presented a number of approaches one could take to classifier graphs.  Importantly, when the vertex labeling function is unavailable, one must deal with this uncertainty somehow.  We compare a number of approaches on both simulated and connectome data.  A multiple-restart Frank-Wolfe approach to approximating QAP outperforms previous state-of-the-art approaches in terms of approximating the graph matching problem.  Simulations demonstrate that only the first iteration of such an iterative algorithm, starting from the identity matrix, yields classification performance better than chance.  Moreover, the first iteration is identical to LAP, which is a linear problem with linear and non-negativity constraints, and therefore can be solved quite easily.  

On a connectome dataset, we compare the performance of various \qap classification algorithms with several graph invariant (GI) based strategies.  Of the algorithms that we tried, a graph invariant approach was most effective, even though, in theory, a QAP based approach could have done better (compare the first and last columns of Table \ref{tab:connectome}).  

These analyses leave many open questions.  Perhaps most interestingly, when might one expect a QAP-based approach to outperform a GI-based approach?  Resorting to a generative model, it should be clear that if the class conditional difference is independent of the vertex labels, then there is no reason to even try to implement graph matching.  However, if one believes that the labeling function might convey some class-conditional signal (as in the connectome data), then QAP-based approaches could outperform any approach that ignores the labeling function.  Which QAP-based approach to use in such a scenario, however, will depend on many factors, including the assumed model and computational resources.










% use section* for acknowledgement
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
  \section*{Acknowledgment}
\fi


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


\bibliography{/Users/jovo/Research/latex/library}
\bibliographystyle{IEEEtran}

\begin{IEEEbiography}{Joshua T. Vogelstein}
Joshua T. Vogelstein is a spritely young man, engorphed in a novel post-buddhist metaphor.

\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiographynophoto}{William R. Gray}
William R. Gray graduated from Vanderbilt University in 2003 with a Bachelor’s degree in electrical engineering, and received his MS in electrical engineering in 2005 from the University of Southern California.  Currently, Will is a PhD student in electrical engineering at The Johns Hopkins University, where he is conducting research in the areas of connectivity, signal and image processing, and machine learning.  He is also a member of the technical staff at the Johns Hopkins University Applied Physics Laboratory, where he manages projects in the Biomedicine and Undersea Warfare business areas.  Will is a member of IEEE, Eta Kappa Nu, and Tau Beta Pi
\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

\begin{IEEEbiographynophoto}{R. Jacob Vogelstein}
R. Jacob Vogelstein received the Sc.B. degree in neuroengineering from Brown University, Providence, RI, and the Ph.D. degree in biomedical engineering from the Johns Hopkins University School of Medicine, Baltimore, MD.  He currently oversees the Applied Neuroscience programs at the Johns Hopkins University (JHU) Applied Physics Laboratory as an Assistant Program Manager, and has an appointment as an Assistant Research Professor at the JHU Whiting School of Engineering’s Department of Electrical and Computer Engineering. He has worked on neuroscience technology for over a decade, focusing primarily on neuromorphic systems and closed-loop brain–machine interfaces. His research has been featured in a number of prominent scientific and engineering journals including the IEEE Transactions on Neural Systems and Rehabilitation Engineering, the IEEE Transactions on Biomedical Circuits and Systems, and the IEEE Transactions on Neural Networks.  
\end{IEEEbiographynophoto}

\begin{IEEEbiography}{Carey E. Priebe}
Buddha in training.
\end{IEEEbiography}

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
% \enlargethispage{-5in}

\end{document}



